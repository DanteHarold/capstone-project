# -*- coding: utf-8 -*-
"""caps_naive_Bayes_modelo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ks-27NWyvHJq9se5LLqIvRL3iiyluIQy
"""

import pandas as pd
from sklearn.naive_bayes import GaussianNB  # Importando Naive Bayes
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

data = pd.read_json('/content/sample_data/dataset.json')

# Separate the characteristics (X) and the target variable (y)
X = data.drop('Indicator', axis=1)
y = data['Indicator']

# Standardize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split data into training (80%) and test (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the Naive Bayes model
model = GaussianNB()
model.fit(X_train, y_train)

# Add the new user's characteristics
new_answers = [2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1 ]  # Completa con las respuestas del nuevo usuario

# Standardize the new user's responses
new_answers = scaler.transform([new_answers])

# Make the prediction for the new user
new_user_prediction = model.predict(new_answers)
print(f'Prediction for the new user: {new_user_prediction[0]}')

# Evaluate the model on the test set
precision = model.score(X_test, y_test)
print(f'Model accuracy on test set: {precision}')

# Make predictions on the test set
y_pred = model.predict(X_test)

# Generation of the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualization of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')
plt.title('Naive Bayes')
plt.xlabel('Predictions')
plt.ylabel('Real Values')
plt.show()

# Calcular métricas de rendimiento adicionales
accuracy = accuracy_score(y_test, y_pred)
precision_weighted = precision_score(y_test, y_pred, average='weighted')
recall_weighted = recall_score(y_test, y_pred, average='weighted')
f1_weighted = f1_score(y_test, y_pred, average='weighted')

# Mostrar las métricas de rendimiento
print(f'Accuracy: {accuracy}')
print(f'Precision (Weighted): {precision_weighted}')
print(f'Recall (Weighted): {recall_weighted}')
print(f'F1 Score (Weighted): {f1_weighted}')

