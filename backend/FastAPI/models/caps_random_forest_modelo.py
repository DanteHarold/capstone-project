# -*- coding: utf-8 -*-
"""caps_random_forest_modelo(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UBM9fy-cnfMBH7JHW4d-oTxSy-53d1Xl
"""

# Importa las bibliotecas necesarias
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt

# Carga el conjunto de datos
data = pd.read_json('/content/sample_data/dataset.json')

# Separa las características (X) y la variable objetivo (y)
X = data.drop('Indicator', axis=1)  # Ajusta el nombre de la variable objetivo
y = data['Indicator']

# Estandariza las características si es necesario
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Divide los datos en conjuntos de entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crea y entrena el modelo de Random Forest
model = RandomForestClassifier(random_state=42)  # Puedes ajustar parámetros adicionales si es necesario
model.fit(X_train, y_train)

# Agrega las características del nuevo usuario (supongamos que estas están en una lista 'nuevas_respuestas')
nuevas_respuestas = [2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1,2, 1, 1 ]  # Completa con las respuestas del nuevo usuario

# Estandariza las respuestas del nuevo usuario
nuevas_respuestas = scaler.transform([nuevas_respuestas])

# Realiza la predicción para el nuevo usuario
prediccion_nuevo_usuario = model.predict(nuevas_respuestas)
print(f'Predicción para el nuevo usuario: {prediccion_nuevo_usuario[0]}')

# Evalúa el modelo en el conjunto de prueba
precision = model.score(X_test, y_test)
print(f'Precisión del modelo en el conjunto de prueba: {precision}')

# Realiza las predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Generación de la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)

# Visualización de la matriz de confusión
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')
plt.title('Random Forest')
plt.xlabel('Predictions')
plt.ylabel('Real Values')
plt.show()

# Calcular métricas de rendimiento adicionales
accuracy = accuracy_score(y_test, y_pred)
precision_weighted = precision_score(y_test, y_pred, average='weighted')
recall_weighted = recall_score(y_test, y_pred, average='weighted')
f1_weighted = f1_score(y_test, y_pred, average='weighted')

# Mostrar las métricas de rendimiento
print(f'Accuracy: {accuracy}')
print(f'Precision (Weighted): {precision_weighted}')
print(f'Recall (Weighted): {recall_weighted}')
print(f'F1 Score (Weighted): {f1_weighted}')

# Calcular métricas de rendimiento adicionales
accuracy = accuracy_score(y_test, y_pred)
precision_weighted = precision_score(y_test, y_pred, average='weighted')
recall_weighted = recall_score(y_test, y_pred, average='weighted')
f1_weighted = f1_score(y_test, y_pred, average='weighted')

# Mostrar las métricas de rendimiento
print(f'Accuracy: {accuracy}')
print(f'Precision (Weighted): {precision_weighted}')
print(f'Recall (Weighted): {recall_weighted}')
print(f'F1 Score (Weighted): {f1_weighted}')